{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cokenet_model import CokeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CokeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_coke = 'dataset/custom_trainable/coke'\n",
    "dir_not_coke = 'dataset/custom_trainable/not_coke'\n",
    "validation_coke = 'dataset/custom_trainable/val_coke'\n",
    "validation_not_coke = 'dataset/custom_trainable/val_not_coke'\n",
    "output_shape=160\n",
    "coke, not_coke = True, True\n",
    "default_transformations_coke = ['flip_vertical_np']\n",
    "default_transformations_not_coke = ['flip_rotate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.retrain(dir_coke, dir_not_coke, validation_coke, validation_not_coke, default_transformations_coke, \n",
    "             default_transformations_not_coke, {'max_epochs': 4, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(self, dir_positive, dir_negative, dir_val_positive, dir_val_negative, transformation_positive, \n",
    "            transformation_negative, model_parameters={}, augmentation_training=True, augmentation_validation=False, \n",
    "            output_shape=160, severity = list(map(lambda x: x+1, np.arange(3))), delete_metadata=True):\n",
    "    \n",
    "        \n",
    "    self.model = retrain_model(model=self.model, dir_coke=dir_positive, dir_not_coke=dir_negative, \n",
    "           model_params=model_parameters, dir_val_coke=dir_val_positive, dir_val_not_coke=dir_val_negative, \n",
    "        default_transformations_coke=transformation_positive, default_transformations_not_coke=transformation_negative, \n",
    "        augmentation_training=augmentation_training, augmentation_validation=augmentation_validation, \n",
    "        output_shape=output_shape, severity=severity)\n",
    "    # TODO : Delete all created folders\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, dir_coke, dir_not_coke, model_params, dir_val_coke, dir_val_not_coke, default_transformations_coke, \n",
    "          default_transformations_not_coke, augmentation_training, augmentation_validation, output_shape, severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = model.get_model()\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(self, dir_positive, dir_negative, dir_val_positive, dir_val_negative, transformation_positive, \n",
    "            transformation_negative, model_parameters={}, delete_metadata=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrainable_module import retrain_model\n",
    "from cokenet_model import CokeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_coke = 'dataset/custom_trainable/coke'\n",
    "dir_not_coke = 'dataset/custom_trainable/not_coke'\n",
    "validation_coke = 'dataset/custom_trainable/val_coke'\n",
    "validation_not_coke = 'dataset/custom_trainable/val_not_coke'\n",
    "output_shape=160\n",
    "coke, not_coke = True, True\n",
    "default_transformations_coke = ['flip_vertical_np']\n",
    "default_transformations_not_coke = ['flip_rotate']\n",
    "model = CokeModel().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(self, dir_positive, dir_negative, dir_val_positive, dir_val_negative, transformation_positive, \n",
    "            transformation_negative, model_parameters={}, delete_metadata=True):\n",
    "    self.model = retrain_model(self.model, dir_positive, dir_negative, dir_val_positive, dir_val_negative, \n",
    "                              transformation_positive, transformation_negative, model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, dir_val_coke=validation_coke, \n",
    "                  dir_val_not_coke=validation_not_coke, default_transformations_coke=default_transformations_coke, \n",
    "                  default_transformations_not_coke=default_transformations_not_coke, \n",
    "                  model_params={'max_epochs':5, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, \n",
    "                      default_transformations_coke=default_transformations_coke, \n",
    "                      default_transformations_not_coke=default_transformations_not_coke, \n",
    "                      model_params={'max_epochs':1, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from data_preprocessor import TransformDataset\n",
    "from functools import reduce\n",
    "from cokenet_mode`l import CokeModel\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from rectified_adam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapped_list(path):\n",
    "    return [str(file) for r, _, f in os.walk(path) for file in f if any(map(str(file).lower().__contains__, ['.png', '.jpg', '.jpeg']))]  \n",
    "\n",
    "def resize_image(img_path, output_shape):\n",
    "    im = imread(img_path)\n",
    "    resized = cv2.resize(im, (output_shape, output_shape), interpolation=cv2.INTER_AREA)\n",
    "    return cv2.normalize(resized, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, \n",
    "                                 dtype = cv2.CV_32F).astype(np.uint8)\n",
    "\n",
    "def resize_directory(base_path, file_lst, output_shape=160):\n",
    "    for im_file in file_lst:\n",
    "        rel_path = os.path.join(base_path, im_file)\n",
    "        try:\n",
    "            if imread(rel_path).shape == (output_shape, output_shape, 3):\n",
    "                continue\n",
    "            resized_im = resize_image(rel_path, output_shape)\n",
    "            resized_im[resized_im<0] = 0\n",
    "            plt.imsave(os.path.join(base_path, im_file), resized_im)\n",
    "            if imread(os.path.join(base_path, im_file)).shape == (output_shape, output_shape, 4):\n",
    "                resized_im = imread(rel_path)[:, :, :3]\n",
    "                resized_im[resized_im<0] = 0\n",
    "                plt.imsave(os.path.join(base_path, im_file), resized_im)\n",
    "        except:\n",
    "            os.remove(rel_path)\n",
    "    return\n",
    "\n",
    "def create_augmentation_set(original_path, transformations, severity):\n",
    "    output_path = original_path + '_augmentation'\n",
    "    file_lst = get_mapped_list(original_path)\n",
    "    func = TransformDataset()\n",
    "    has_severity = ['rotate_np', 'flip_rotate', 'perform_swirl_transformation', 'perform_random_affine_transform', \n",
    "                    'add_multiplicative_noise', 'add_shot_noise', 'add_gaussian_noise', 'add_impulse_noise', \n",
    "                    'add_glass_blur', 'add_gaussian_blur']\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    for im_file in file_lst:\n",
    "        im = imread(os.path.join(original_path, im_file))\n",
    "        file_name, extension = im_file.split('.')\n",
    "        \n",
    "        for transF in transformations:\n",
    "            if transF not in has_severity:\n",
    "                try:\n",
    "                    plt.imsave(os.path.join(output_path, \".\".join([\"_\".join([file_name, transF]), extension])), \n",
    "                               func.return_function(transF, im))\n",
    "                except:\n",
    "                    print (\"Failed to augment file = {}\".format(file_name))\n",
    "                    continue\n",
    "            else:\n",
    "                for severity_ in severity:\n",
    "                    try:\n",
    "                        plt.imsave(os.path.join(output_path, \".\".join([\"_\".join([file_name, transF]), extension])), \n",
    "                           func.return_function(transF, im, severity_))\n",
    "                    except:\n",
    "                        print (\"Failed to augment file = {}\".format(file_name))\n",
    "                        continue\n",
    "        #print (\"Successfully created Augmentation Set for {}\".format(im_file))\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prepare_directories(dir_, transformations, label, severity, create_augmentation=True, \n",
    "                                data_map=[], paths_map=[], label_map=[]):\n",
    "    dataset = get_mapped_list(dir_)\n",
    "    resize_directory(dir_, dataset)\n",
    "    \n",
    "    data_map.append(dataset)\n",
    "    paths_map.append(dir_)\n",
    "    label_map.append(label)\n",
    "    \n",
    "    if create_augmentation:\n",
    "        dir_augmented = create_augmentation_set(dir_, transformations, severity)\n",
    "        dataset_augmented = get_mapped_list(dir_augmented)\n",
    "        data_map.append(dataset_augmented)\n",
    "        paths_map.append(dir_augmented)\n",
    "        label_map.append(label)\n",
    "        \n",
    "    return data_map, paths_map, label_map\n",
    "\n",
    "def create_dataset(data_map, path_map, label_map, output_shape):\n",
    "    h, w, c = output_shape, output_shape, 3\n",
    "    size_data = reduce(lambda x,y: x+y, map(lambda x: len(x), data_map))\n",
    "    X = np.zeros((size_data, h, w, c), dtype=np.float32)\n",
    "    Y = np.zeros((size_data))\n",
    "    x_ptr = 0\n",
    "    for idx in range(len(data_map)):\n",
    "        if label_map[idx]:\n",
    "            Y[x_ptr:x_ptr+len(data_map[idx])] = np.ones(len(data_map[idx]))\n",
    "        for file in data_map[idx]:\n",
    "            im = imread(os.path.join(path_map[idx], file)).astype(np.float32)\n",
    "            if im.shape != (h, w, c):\n",
    "                im = im[:, :, :c]\n",
    "            X[x_ptr] = im\n",
    "            x_ptr += 1\n",
    "    return X, Y\n",
    "\n",
    "def prepare_dataset_for_retraining (dir_coke, dir_not_coke, default_transformations_coke, \n",
    "                                    default_transformations_not_coke, output_shape, severity, create_augmentation=True):\n",
    "    if len(dir_coke) == 0 and len(dir_not_coke) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    if len(default_transformations_coke) == 0:\n",
    "        default_transformations_coke = ['flip_vertical_np', 'flip_horizontal_np', 'rotate_np', 'flip_rotate', \n",
    "        'perform_swirl_transformation', 'perform_random_affine_transform', 'add_multiplicative_noise', 'add_shot_noise', \n",
    "        'add_gaussian_noise', 'add_impulse_noise', 'add_glass_blur', 'add_gaussian_blur', 'random_image_eraser']\n",
    "    if len(default_transformations_not_coke) == 0:\n",
    "        default_transformations_not_coke = ['flip_rotate', 'random_image_eraser']\n",
    "    \n",
    "    all_data, all_paths, is_label = process_prepare_directories(dir_=dir_coke, transformations=default_transformations_coke, \n",
    "        label=True, severity=severity, create_augmentation=create_augmentation, data_map=[], paths_map=[], label_map=[])\n",
    "    all_data, all_paths, is_label = process_prepare_directories(dir_=dir_not_coke, \n",
    "        transformations=default_transformations_not_coke, label=False, severity=severity, create_augmentation=create_augmentation, \n",
    "        data_map=all_data, paths_map=all_paths, label_map=is_label)\n",
    "    \n",
    "    X, Y = create_dataset(all_data, all_paths, is_label, output_shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, dir_coke, dir_not_coke, dir_val_coke='', dir_val_not_coke='', default_transformations_coke=[], \n",
    "                  default_transformations_not_coke=[], augmentation_training=True, augmentation_validation=False, \n",
    "                  output_shape=160, severity = list(map(lambda x: x+1, np.arange(3))), model_params={}):\n",
    "    # Creating the training dataset\n",
    "    X_train, y_train = prepare_dataset_for_retraining(dir_coke, dir_not_coke, default_transformations_coke, \n",
    "                                  default_transformations_not_coke, output_shape, severity, augmentation_training)\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    \n",
    "    if len(dir_val_coke) != 0 or len(dir_val_not_coke) !=0: # Use only when either of the path is specified\n",
    "        # Creating the validation dataset\n",
    "        X_val, y_val = prepare_dataset_for_retraining(dir_val_coke, dir_val_not_coke,\n",
    "                 default_transformations_coke, default_transformations_not_coke, output_shape, severity, augmentation_validation)\n",
    "    \n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "    # Default Model parameters\n",
    "    default_max_epochs, default_split_size, default_batch_size = 10, 6144, 3072\n",
    "    default_model_save_path = 'cokenet/model'\n",
    "    \n",
    "    max_epochs = model_params.get('max_epochs') or default_max_epochs\n",
    "    split_size = model_params.get('split_size') or default_split_size\n",
    "    batch_size = model_params.get('batch_size') or default_batch_size\n",
    "    model_path = model_params.get('external_model_path') or ''\n",
    "    \n",
    "    idxs = np.arange(X_train.shape[0])\n",
    "    for chunk in np.array_split(idxs, int(np.ceil(X_train.shape[0] / split_size))):\n",
    "        X_current, y_current = X_train[chunk], y_train[chunk]\n",
    "        if len(dir_val_coke) != 0 or len(dir_val_not_coke) !=0:\n",
    "            model.fit(X_current, y_current, epochs=max_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "        else:\n",
    "            model.fit(X_current, y_current, epochs=max_epochs, batch_size=batch_size)\n",
    "    \n",
    "        if len(model_path) > 0:\n",
    "            if not os.path.exists(model_path):\n",
    "                os.makedirs(model_path, exist_ok=True)\n",
    "            model.save(os.path.join(model_path, 'AlexNet.hdf5'))\n",
    "        else:\n",
    "            model.save(os.path.join(default_model_save_path, 'AlexNet.hdf5'))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_coke = 'dataset/custom_trainable/coke'\n",
    "dir_not_coke = 'dataset/custom_trainable/not_coke'\n",
    "validation_coke = 'dataset/custom_trainable/val_coke'\n",
    "validation_not_coke = 'dataset/custom_trainable/val_not_coke'\n",
    "output_shape=160\n",
    "coke, not_coke = True, True\n",
    "default_transformations_coke = ['flip_vertical_np']\n",
    "default_transformations_not_coke = ['flip_rotate']\n",
    "model = CokeModel().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, dir_val_coke=validation_coke, \n",
    "                  dir_val_not_coke=validation_not_coke, default_transformations_coke=default_transformations_coke, \n",
    "                  default_transformations_not_coke=default_transformations_not_coke, \n",
    "                  model_params={'max_epochs':5, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, \n",
    "                      default_transformations_coke=default_transformations_coke, \n",
    "                      default_transformations_not_coke=default_transformations_not_coke, \n",
    "                      model_params={'max_epochs':6, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, \n",
    "                      default_transformations_coke=default_transformations_coke, \n",
    "                      default_transformations_not_coke=default_transformations_not_coke, \n",
    "                      augmentation_training=False, augmentation_validation=False,\n",
    "                      model_params={'max_epochs':7, 'external_model_path': 'cokenet/additional_model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke=dir_not_coke, \n",
    "                      default_transformations_coke=default_transformations_coke, \n",
    "                      default_transformations_not_coke=default_transformations_not_coke, \n",
    "                      augmentation_training=False, augmentation_validation=False,\n",
    "                      model_params={'max_epochs':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(model=model, dir_coke=dir_coke, dir_not_coke='', \n",
    "                      default_transformations_coke=default_transformations_coke, \n",
    "                      default_transformations_not_coke=default_transformations_not_coke, \n",
    "                      augmentation_training=False, augmentation_validation=False,\n",
    "                      model_params={'max_epochs':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, dir_coke, dir_not_coke, dir_val_coke='', dir_val_not_coke='', default_transformations_coke=[], \n",
    "                  default_transformations_not_coke=[], augmentation_training=True, augmentation_validation=False, \n",
    "                  output_shape=160, model_params={}):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CokeModel().get_model()\n",
    "model_params = {}\n",
    "# Default Model parameters\n",
    "default_max_epochs, default_split_size, default_batch_size = 10, 6144, 3072\n",
    "default_model_save_path = 'cokenet/model'\n",
    "\n",
    "max_epochs = model_params.get('max_epochs') or default_max_epochs\n",
    "split_size = model_params.get('split_size') or default_split_size\n",
    "batch_size = model_params.get('batch_size') or default_batch_size\n",
    "model_path = model_params.get('external_model_path') or ''\n",
    "\n",
    "idxs = np.arange(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(X_train.shape[0])\n",
    "for chunk in np.array_split(idxs, int(np.ceil(X_train.shape[0] / split_size))):\n",
    "    X_current, y_current = X_train[chunk], y_train[chunk]\n",
    "    model.fit(X_current, y_current, epochs=max_epochs, batch_size=batch_size, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_current.shape, y_current.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
